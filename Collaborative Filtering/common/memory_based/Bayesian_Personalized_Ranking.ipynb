{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BPR (Bayesian Personalized Ranking)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Теорема Байеса\n",
    "\n",
    "В основе баесовских методов лежит формула Байеса:\n",
    "\n",
    "$$\n",
    "P(A \\mid B) = \\frac{P(B \\mid A) \\cdot P(A)}{P(B)}\n",
    "$$\n",
    "\n",
    "Где:  \n",
    "- $P(A)$ — априорная вероятность события $A$\n",
    "- $P(B)$ — априорная вероятность события $B$  \n",
    "- $P(B \\mid A)$ — вероятность события $B$ при условии $A$  \n",
    "- $P(A \\mid B)$ — апостериорная вероятность события $A$ при наличии $B$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BPR (Bayesian Personalized Ranking)\n",
    "\n",
    "BPR (Bayesian Personalized Ranking) — это метод коллаборативной фильтрации, разработанный специально для рекомендаций с неявными данными, такими как клики, просмотры или лайки. В отличие от стандартных подходов, основанных на явных оценках (рейтингах), BPR лучше справляется с ситуациями, когда данные не содержат явных оценок.\n",
    "\n",
    "### Идея BPR:\n",
    "Основная идея BPR заключается в следующем:\n",
    "\n",
    "- У пользователя больше интерес к элементам, с которыми он взаимодействовал (например, прочитал новость), чем к тем, с которыми не взаимодействовал.\n",
    "- Задача метода — ранжировать взаимодействованные объекты выше невзаимодействованных.\n",
    "\n",
    "### Пример:\n",
    "Если пользователь **U** прочитал новость **A**, но не читал новость **B**, модель должна предсказать, что **A** предпочтительнее **B** для пользователя **U**.\n",
    "\n",
    "### Формулировка задачи:\n",
    "Пусть **U** — множество пользователей, **I** — множество новостей.  \n",
    "Для пользователя **u** существует пара взаимодействий (положительное — **i**, отрицательное — **j**).  \n",
    "- Положительные взаимодействия — новости, которые пользователь прочитал.\n",
    "- Отрицательные взаимодействия — случайные новости, которые пользователь не читал.  \n",
    "\n",
    "Цель: максимизировать вероятность того, что пользователь предпочтет **i** над **j**.\n",
    "\n",
    "### Функция вероятности и ранжирования:\n",
    "Для каждой тройки (**u**, **i**, **j**), где:\n",
    "\n",
    "- **u** — пользователь,\n",
    "- **i** — положительное взаимодействие (прочитанная новость),\n",
    "- **j** — отрицательное взаимодействие (непрочитанная новость),\n",
    "\n",
    "максимизируем вероятность:\n",
    "\n",
    "$$\n",
    "P(i >_u j) = \\sigma(\\hat{x}_{ui} - \\hat{x}_{uj})\n",
    "$$\n",
    "\n",
    "где:\n",
    "\n",
    "- $\\sigma$ — сигмоида: $$\\sigma(x) = \\frac{1}{1 + e^{-x}}$$\n",
    "- $\\hat{x}_{ui}$ — предсказанная \"полезность\" объекта **i** для пользователя **u**.\n",
    "- $\\hat{x}_{uj}$ — предсказанная \"полезность\" объекта **j** для пользователя **u**.\n",
    "\n",
    "### Функция потерь:\n",
    "Оптимизация происходит через максимизацию логарифма правдоподобия:\n",
    "\n",
    "$$\n",
    "L = \\sum_{(u, i, j) \\in D} \\log(\\sigma(\\hat{x}_{ui} - \\hat{x}_{uj})) - \\lambda \\| \\Theta \\|_2^2\n",
    "$$\n",
    "\n",
    "где:\n",
    "\n",
    "- **D** — множество всех возможных тройных комбинаций (**u**, **i**, **j**).\n",
    "- **λ** — коэффициент регуляризации для контроля переобучения.\n",
    "- **Θ** — параметры модели (матрицы эмбеддингов пользователей и новостей).\n",
    "\n",
    "### Реализация модели:\n",
    "Обычно BPR используется в сочетании с матричной факторизацией. Эмбеддинги пользователей и новостей обучаются одновременно:\n",
    "\n",
    "$$\n",
    "\\hat{x}_{ui} = \\langle p_u, q_i \\rangle = \\sum_{f=1}^F p_{uf} \\cdot q_{if}\n",
    "$$\n",
    "\n",
    "где:\n",
    "\n",
    "- $p_u$ — вектор эмбеддинга пользователя **u**.\n",
    "- $q_i$ — вектор эмбеддинга новости **i**.\n",
    "- **F** — размерность скрытого пространства.\n",
    "\n",
    "### Пошаговый алгоритм BPR:\n",
    "1. **Инициализация**: случайная инициализация эмбеддингов пользователей и новостей.\n",
    "2. **Формирование триплетов** (**u**, **i**, **j**): Для каждого пользователя **u** выбирается положительная новость **i**. Случайным образом выбирается отрицательная новость **j**.\n",
    "3. **Обновление эмбеддингов**: используется стохастический градиентный спуск (SGD) для обновления эмбеддингов.\n",
    "4. **Оптимизация**: максимизация правдоподобия или минимизация функции потерь.\n",
    "5. **Рекомендации**: на основе полученных эмбеддингов строится ранжированный список рекомендаций.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
